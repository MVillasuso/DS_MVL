{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit61836de9583b4678983c2459e76af05f",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nivel intermedio:\n",
    "\n",
    "Hacer con objetivo de preparar entrevista técnica y tener un código reutilizable, útil y funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "Crea un programa que pregunte al usuario qué tipo de algoritmo desea utilizar (entre regresión lineal, regresión logística y Knn).\n",
    "\n",
    "Se presupone que el usuario proporcionará un dataframe con los datos a entrenar, el nombre de la columna target que está en el dataframe.\n",
    "\n",
    "El programa debe contener, como mínimo, estas tres funciones tal que así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\"choose_model\" recibe:\n",
    "\n",
    "- 'option_user': la opción del usuario. \n",
    "- 'params': es un diccionario que puede contener ciertos parámetros necesarios para la creación de los modelos (por ejemplo, el valor k para el algoritmo Knn). Por defecto, su valor es None.\n",
    "\n",
    "Deberá crear el modelo necesario sin entrenar, retornándolo al final.\n",
    "\n",
    "----------------\n",
    "\n",
    "\"train_model\" recibe:\n",
    "\n",
    "- 'model': el modelo sin entrenar elegido por el usario\n",
    "- 'df': el dataframe tratado y limpio que contiene todos los datos del conjunto de entrenamiento y de test, incluyendo el target. \n",
    "- 'target_name': el nombre de la columna que representa el target.\n",
    "\n",
    "Retornará el modelo entrenado con los datos y la precisión del modelo.\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "\"main\": \n",
    "\n",
    "Es la función que ha de ser ejecutada cada vez que queremos lanzar el programa. \n",
    "\n",
    "Al final, mostrará la precisión del modelo entrenado y retornará el modelo entreado.\n",
    "\n",
    "----------------\n"
   ]
  },
  {
   "source": [
    "### Regresión:  \n",
    "Linear Regression  \n",
    "SVM (versión regresión SVR)  \n",
    "Polinominal Regression  \n",
    "Random Forest (versión regresión)  \n",
    "### Clasificación:    \n",
    "SVM (versión regresión SVC)  \n",
    "Knn  \n",
    "Random Forest (versión clasificación)  \n",
    "Xgboost (si todo OK)  \n",
    "Logistic regression  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# Modelos de regresion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Modelos de clasificacion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(tipo, option_user, params=None):\n",
    "    if tipo ==1:\n",
    "        model_dicc={1:LinearRegression(), \n",
    "                    2:PolynomialFeatures(degree=params[\"degree\"]),\n",
    "                    3:SVR(kernel=params[\"kernel\"], C=params[\"C\"], gamma=params[\"gamma\"]),\n",
    "                    4:RandomForestRegressor(n_estimators=params[\"n_estimators\"])}\n",
    "    else:\n",
    "        model_dicc={1:LogisticRegression(penalty= params[\"penalty\"]), \n",
    "                    2:KNeighborsClassifier(n_neighbors=params[\"k\"]), \n",
    "                    3:SVC(kernel=params[\"kernel\"], C=params[\"C\"], degree=params[\"degree\"]), \n",
    "                    4:RandomForestClassifier(n_estimators=params[\"n_estimators\"]), \n",
    "                    5:XGBClassifier(n_estimators=params[\"n_estimators\"])}\n",
    "    model = model_dicc[option_user]\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, df, target_name,poly):\n",
    "    lista_cols = df.columns.to_list()\n",
    "    lista_cols.remove(target_name)\n",
    "    X=df[lista_cols].values\n",
    "    y=df[target_name].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize)\n",
    "\n",
    "    if poly == True:\n",
    "        X_poly = model.fit_transform(X_train, y_train)\n",
    "        model=LinearRegression()\n",
    "        print (X_poly.shape, y_train.shape)\n",
    "        model_trained = model.fit(X_poly,y_train) \n",
    "        y_pred = model.predict(X_poly)\n",
    "        accuracy= r2_score(y_train, y_pred)\n",
    "    else:\n",
    "        model_trained = model.fit(X_train,y_train)      \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    #Entrenarlo con todos los datos\n",
    "    #model_trained = model.fit(X,y)  \n",
    "    #accuracy = model.score(X, y)      \n",
    "    \n",
    "    return model_trained, accuracy\n",
    "\n",
    "\n",
    "def main():\n",
    "    tipo_modl = int(input (\"Indica el tipo: \" + \n",
    "                            \"(1):Regresión, \" + \n",
    "                            \"(2): Clasificación\"))\n",
    "    if tipo_modl ==1:\n",
    "        sel_model = int(input (\"Indica el modelo a utilizar: \" +\n",
    "                    \"(1): Regr.Lineal, \"+\n",
    "                    \"(2): Regresion Polinómica, \"+\n",
    "                    \"(3): SVR, \"+ \n",
    "                    \"(4): Random Forest Regressor\"))\n",
    "    else:\n",
    "        sel_model = int(input (\"Indica el modelo a utilizar: \"+\n",
    "                    \"(1): Regr.Logística ,\"+ \n",
    "                    \"(2): KNN ,\"+\n",
    "                    \"(3): SVC ,\"+\n",
    "                    \"(4): Random Forest Classifier ,\"+\n",
    "                    \"(5): XGBoost\"))\n",
    "        \n",
    "    mod = choose_model(int(tipo_modl),int(sel_model),param)    #Selección del modelo \n",
    "    if tipo_modl==1 and sel_model==2:      #Regresión polinómica\n",
    "        poly =True\n",
    "    else:\n",
    "        poly=False\n",
    "\n",
    "    model_trained, accuracy = train_model(mod,df,target_col,poly=poly) # Entrenamiento del modelo \n",
    "    print(\"Accuracy: \", round(accuracy*100,2), \"%\")     #Precisión del modelo\n",
    "    return model_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables globales para la prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # opciones de kernel ['rbf','linear','poly']\n",
    "    param = {\"k\":5, \"degree\":3, \"kernel\":'rbf', \"C\":100, \"gamma\":'1', \"epsilon\":.1, \"coef0\":1, \n",
    "            \"n_estimators\":10, \"penalty\": \"l2\"}\n",
    "    tsize=0.20\n",
    "    poly = False\n",
    "\n",
    "    #Prueba con datos para modelos de regresión\n",
    "    #df = pd.read_csv(\"/Users/purbina/Desktop/THE_BRIDGE/DS_MVL/PROYECTOS/week8/day2/data/USA_Housing.csv\")\n",
    "    #df.drop(['Address'], axis=1, inplace=True)\n",
    "    #target_col = \"Price\"\n",
    "\n",
    "    #Prueba con datos para Modelos de clasificación\n",
    "    df = pd.read_csv('/Users/purbina/Desktop/THE_BRIDGE/DS_MVL/PROYECTOS/week8/day4/data/iris.csv')\n",
    "    target_col = \"variety\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy:  96.67 %\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Haz que el programa sea capaz de predecir un nuevo ejemplo del modelo elegido y entrenado con la siguiente función:\n",
    "----------------\n",
    "\n",
    "\"predict_new_data\" recibe:\n",
    "\n",
    "- 'model_trained': el modelo entrenado elegido por el usario\n",
    "- 'to_pred': los datos del nuevo ejemplo a predecir.\n",
    "\n",
    "Retornará y mostrará por pantalla la predicción.\n",
    "\n",
    "----------------\n",
    "\n",
    "Se presupone que el usuario proporcionará los datos del nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(model_trained, to_pred):\n",
    "    print(model_trained)\n",
    "    print (to_pred)\n",
    "    y_pred = model_trained.predict(to_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con Algoritmos de Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba para el modelo de regresión\n",
    "#new_home = np.array([[100000.0, 20.0, 8.0, 9.0, 100000.0], [200000.0, 40.0, 16.0, 18.0, 110000.0]])\n",
    "#val_pred = new_home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con Algoritmos de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba con modelos de clasificación\n",
    "val_pred=[[15.7,2.8,9.5,0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Virginica'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-a321d6a88421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_estim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_trained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Valores Estimados con \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_estim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-084d708b0643>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpoly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmodel_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Entrenamiento del modelo con los datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#Precisión del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-084d708b0643>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, df, target_name, poly)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Virginica'"
     ]
    }
   ],
   "source": [
    "mod_trained = main()\n",
    "val_estim = predict_new_data(mod_trained,val_pred)\n",
    "print(\"Valores Estimados con \", mod_trained, \": \",val_estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}